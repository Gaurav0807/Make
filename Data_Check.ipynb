{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8241054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b00063c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "19765cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FINREFERENCE</th>\n",
       "      <th>Pending No of Inst</th>\n",
       "      <th>Financing Tenure</th>\n",
       "      <th>Finance Amount</th>\n",
       "      <th>Business_Type</th>\n",
       "      <th>Bucket</th>\n",
       "      <th>Employees in Business</th>\n",
       "      <th>Business Category</th>\n",
       "      <th>Registered_Business</th>\n",
       "      <th>Financing_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Current Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Pincode</th>\n",
       "      <th>PREVIOUS_FINANCING</th>\n",
       "      <th>LIVE_FINANCING</th>\n",
       "      <th>CLOSED_FINANCING</th>\n",
       "      <th>CUSTOMERID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HO00CD00000053</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4000000</td>\n",
       "      <td>Consumer Durables</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>KORAS ROAD,VARTAK NAGAR B-7,403 VEDANT COMPLEX...</td>\n",
       "      <td>Thane</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>400606</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10000077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HO00CD00000055</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1599000</td>\n",
       "      <td>Consumer Durables</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>LAXAMI CHAWL, SURVE CHAWL, RM NO 1,THANE  LAX...</td>\n",
       "      <td>Thane</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>400606</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HO00CD00000140</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3450000</td>\n",
       "      <td>Consumer Durables</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>A 202 KUNAL ASPIREE BALEWADI PUNE  A 202 KUNA...</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>411045</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HO00CD00000142</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1299000</td>\n",
       "      <td>Consumer Durables</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>GAURI HOUSE N L ROAD SOMVAARI BAZAAR MARKETCH...</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>400064</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10000169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FINREFERENCE  Pending No of Inst  Financing Tenure  Finance Amount  \\\n",
       "0  HO00CD00000053                   0                 6         4000000   \n",
       "1  HO00CD00000055                   0                 8         1599000   \n",
       "2  HO00CD00000140                   0                 6         3450000   \n",
       "3  HO00CD00000142                   0                 5         1299000   \n",
       "\n",
       "       Business_Type  Bucket  Employees in Business  Business Category  \\\n",
       "0  Consumer Durables      18                    NaN                NaN   \n",
       "1  Consumer Durables       0                    NaN                NaN   \n",
       "2  Consumer Durables       0                    NaN                NaN   \n",
       "3  Consumer Durables      20                    NaN                NaN   \n",
       "\n",
       "   Registered_Business  Financing_ID  ... Gender  Marital_Status  \\\n",
       "0                  NaN           NaN  ...      M               M   \n",
       "1                  NaN           NaN  ...      M               S   \n",
       "2                  NaN           NaN  ...      M               M   \n",
       "3                  NaN           NaN  ...      M               M   \n",
       "\n",
       "                                     Current Address    City        State  \\\n",
       "0  KORAS ROAD,VARTAK NAGAR B-7,403 VEDANT COMPLEX...   Thane  Maharashtra   \n",
       "1   LAXAMI CHAWL, SURVE CHAWL, RM NO 1,THANE  LAX...   Thane  Maharashtra   \n",
       "2   A 202 KUNAL ASPIREE BALEWADI PUNE  A 202 KUNA...    Pune  Maharashtra   \n",
       "3   GAURI HOUSE N L ROAD SOMVAARI BAZAAR MARKETCH...  Mumbai  Maharashtra   \n",
       "\n",
       "   Pincode  PREVIOUS_FINANCING  LIVE_FINANCING  CLOSED_FINANCING  CUSTOMERID  \n",
       "0   400606                   1               1                 0    10000077  \n",
       "1   400606                   1               0                 1    10000080  \n",
       "2   411045                   1               0                 1    10000173  \n",
       "3   400064                   1               1                 0    10000169  \n",
       "\n",
       "[4 rows x 46 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('cd_jobs_geographical_details.csv')\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fa7a8ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29234 entries, 0 to 29233\n",
      "Data columns (total 46 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   FINREFERENCE             29234 non-null  object \n",
      " 1   Pending No of Inst       29234 non-null  int64  \n",
      " 2   Financing Tenure         29234 non-null  int64  \n",
      " 3   Finance Amount           29234 non-null  int64  \n",
      " 4   Business_Type            29234 non-null  object \n",
      " 5   Bucket                   29234 non-null  int64  \n",
      " 6   Employees in Business    0 non-null      float64\n",
      " 7   Business Category        0 non-null      float64\n",
      " 8   Registered_Business      0 non-null      float64\n",
      " 9   Financing_ID             0 non-null      float64\n",
      " 10  Product                  29234 non-null  object \n",
      " 11  Interest Rate            29234 non-null  float64\n",
      " 12  First Installment Date   29234 non-null  object \n",
      " 13  Last Installment Date    29234 non-null  object \n",
      " 14  Disbursement Date        29234 non-null  object \n",
      " 15  Flexibility in Inst Amt  0 non-null      float64\n",
      " 16  Business Margin          0 non-null      float64\n",
      " 17  Business Sector          0 non-null      float64\n",
      " 18  Seasonality Impact       0 non-null      float64\n",
      " 19  GST Number               0 non-null      float64\n",
      " 20  UID Number               0 non-null      float64\n",
      " 21  Guarantor                0 non-null      float64\n",
      " 22  YearsOfBusiness          0 non-null      float64\n",
      " 23  Co-Borrower              0 non-null      float64\n",
      " 24  Number of Co-Borrower    0 non-null      float64\n",
      " 25  Co-Borrower relation     0 non-null      float64\n",
      " 26  Customer_Name            29234 non-null  object \n",
      " 27  DOB                      29234 non-null  object \n",
      " 28  Occupation               29234 non-null  object \n",
      " 29  Highest_Education        0 non-null      float64\n",
      " 30  Residence_Type           0 non-null      float64\n",
      " 31  Branch                   29234 non-null  object \n",
      " 32  Branch_City              29234 non-null  object \n",
      " 33  Branch_State             29234 non-null  object \n",
      " 34  Phone_Number             29234 non-null  int64  \n",
      " 35  Landline_Number          0 non-null      float64\n",
      " 36  Gender                   29234 non-null  object \n",
      " 37  Marital_Status           29234 non-null  object \n",
      " 38  Current Address          29234 non-null  object \n",
      " 39  City                     29234 non-null  object \n",
      " 40  State                    29234 non-null  object \n",
      " 41  Pincode                  29234 non-null  int64  \n",
      " 42  PREVIOUS_FINANCING       29234 non-null  int64  \n",
      " 43  LIVE_FINANCING           29234 non-null  int64  \n",
      " 44  CLOSED_FINANCING         29234 non-null  int64  \n",
      " 45  CUSTOMERID               29234 non-null  int64  \n",
      "dtypes: float64(19), int64(10), object(17)\n",
      "memory usage: 10.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6777dd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        05-04-79\n",
       "1        09-09-88\n",
       "2        12-10-76\n",
       "3        07-11-89\n",
       "4        21-09-82\n",
       "           ...   \n",
       "29229    10-04-86\n",
       "29230    02-01-89\n",
       "29231    31-07-77\n",
       "29232    28-11-85\n",
       "29233    19-01-90\n",
       "Name: DOB, Length: 29234, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df['DOB']\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "07749495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            Salaried\n",
       "1            Salaried\n",
       "2            Salaried\n",
       "3        selfemployed\n",
       "4            Salaried\n",
       "             ...     \n",
       "29229    selfemployed\n",
       "29230    selfemployed\n",
       "29231    selfemployed\n",
       "29232        Salaried\n",
       "29233        Salaried\n",
       "Name: Occupation, Length: 29234, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Occupation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "388ff528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        KORAS ROAD,VARTAK NAGAR B-7,403 VEDANT COMPLEX...\n",
       "1         LAXAMI CHAWL, SURVE CHAWL, RM NO 1,THANE  LAX...\n",
       "2         A 202 KUNAL ASPIREE BALEWADI PUNE  A 202 KUNA...\n",
       "3         GAURI HOUSE N L ROAD SOMVAARI BAZAAR MARKETCH...\n",
       "4         APARTMENT FLAT NO 505 BULDG NO L 3 C WING FLO...\n",
       "                               ...                        \n",
       "29229     11(2), SHYAMPUR, Gajiwali, Shyampur, Haridwar...\n",
       "29230     S/O Qamaruddin Khan, 49, KAzi AHAMAD NOOR, ZA...\n",
       "29231     4 401 RAVINDRA NIWAS DNC ROAD BEHIND PRAGATI ...\n",
       "29232     Q' C/O: Narmdeshwar Tiwari, Shin Raj Nagar 8 ...\n",
       "29233     CO SANJAY KUMAR SALAWALA DEHRADUN CO SANJAY K...\n",
       "Name: Current Address, Length: 29234, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df['Current Address']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b21f3853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "spark = SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fcf5ce6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+---------------+-------+\n",
      "|CYCLEDAY| EMI|OVER_DUE_AMOUNT| OS_Amt|\n",
      "+--------+----+---------------+-------+\n",
      "|      15|Null|        12160.0|   Null|\n",
      "|      15|Null|       11467.99|   Null|\n",
      "|      02|Null|            0.0|    0.0|\n",
      "|      02|Null|            0.0|    0.0|\n",
      "|      02|Null|            0.0|    0.0|\n",
      "|      02|Null|            0.0|    0.0|\n",
      "|      02|Null|         1792.7| 1792.7|\n",
      "|      02|Null|            0.0|    0.0|\n",
      "|      15|Null|            0.0|   Null|\n",
      "|      15|Null|        1636.52|   Null|\n",
      "|      02|Null|        1069.39|1069.39|\n",
      "|      02|Null|        2926.71|2926.71|\n",
      "|      02|Null|            0.0|    0.0|\n",
      "|      02|Null|         163.74| 163.74|\n",
      "|      02|Null|            0.0|    0.0|\n",
      "|      02|Null|            0.0|    0.0|\n",
      "|      02|Null|            0.0|    0.0|\n",
      "|      02|Null|            0.0|    0.0|\n",
      "|      02|Null|            0.0|    0.0|\n",
      "|      02|Null|            0.0|    0.0|\n",
      "+--------+----+---------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df11=spark.read.csv('C:/Users/Gaurav/Desktop/Mahindra Project/Input Files_MP/Loan_Info_Montly_Snapshot_Level.csv', header=True, inferSchema=True)\n",
    "MergeFile = df11.withColumn(\"CYCLEDAY\", df11.Due_Date.substr(-2, 2))\n",
    "MergeFile = MergeFile.withColumn(\"EMI\",lit(\"Null\"))\n",
    "MergeFile = MergeFile.withColumn('OS_Amt', when(\n",
    "        col('CYCLEDAY') >= date_format(add_months((from_unixtime(unix_timestamp(lit(datetime.datetime.now(\n",
    "        ).strftime(\"%Y-%m-%d\")), 'yyyy-MM-dd')).cast('date')), 0), \"dd\"), (col('EMI'))).otherwise(\n",
    "        col('OVER_DUE_AMOUNT')))\n",
    "MergeFile = MergeFile.select(\"CYCLEDAY\",\"EMI\",\"OVER_DUE_AMOUNT\",\"OS_Amt\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb84984c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FINREFERENCE',\n",
       " 'Pending No of Inst',\n",
       " 'Financing Tenure',\n",
       " 'Finance Amount',\n",
       " 'Business_Type',\n",
       " 'Bucket',\n",
       " 'Employees in Business',\n",
       " 'Business Category',\n",
       " 'Registered_Business',\n",
       " 'Financing_ID',\n",
       " 'Product',\n",
       " 'Interest Rate',\n",
       " 'First Installment Date',\n",
       " 'Last Installment Date',\n",
       " 'Disbursement Date',\n",
       " 'Flexibility in Inst Amt',\n",
       " 'Business Margin',\n",
       " 'Business Sector',\n",
       " 'Seasonality Impact',\n",
       " 'GST Number',\n",
       " 'UID Number',\n",
       " 'Guarantor',\n",
       " 'YearsOfBusiness',\n",
       " 'Co-Borrower',\n",
       " 'Number of Co-Borrower',\n",
       " 'Co-Borrower relation',\n",
       " 'Customer_Name',\n",
       " 'DOB',\n",
       " 'Occupation',\n",
       " 'Highest_Education',\n",
       " 'Residence_Type',\n",
       " 'Branch',\n",
       " 'Branch_City',\n",
       " 'Branch_State',\n",
       " 'Phone_Number',\n",
       " 'Landline_Number',\n",
       " 'Gender',\n",
       " 'Marital_Status',\n",
       " 'Current Address',\n",
       " 'City',\n",
       " 'State',\n",
       " 'Pincode',\n",
       " 'PREVIOUS_FINANCING',\n",
       " 'LIVE_FINANCING',\n",
       " 'CLOSED_FINANCING',\n",
       " 'CUSTOMERID']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.appName('Practise').getOrCreate()\n",
    "#df12 = df11.withColumn(\"Age\", months_between(current_date(),col(\"DOB\")))\n",
    "#df11 = spark.read.csv('cd_jobs_geographical_details.csv', header=True, inferSchema=True).select(\"DOB\")\n",
    "#df11 =  df11.withColumn(\"Age\",122 - df11.DOB.substr(-2,2).cast(\"int\"))\n",
    "df11 = spark.read.csv('cd_jobs_geographical_details.csv', header=True, inferSchema=True)\n",
    "df11.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f03bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = spark.read.csv('cd_jobs_geographical_details.csv', header=True, inferSchema=True).select(\"DOB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "476432c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Loan_Account_Number',\n",
       " 'Customer_ID',\n",
       " 'Loan_Status',\n",
       " 'MORAT/Installment Holiday',\n",
       " 'Installment_Presentment_Flag',\n",
       " 'Due_Date',\n",
       " 'Installment',\n",
       " 'Paid_Date',\n",
       " 'Paid_Amount',\n",
       " 'POS',\n",
       " 'DPD',\n",
       " 'Bucket',\n",
       " 'Last_Month_DPD',\n",
       " 'Last_Month_Bucket',\n",
       " 'Over_Due_Amount',\n",
       " 'Bounce_Status',\n",
       " 'Bureau Scrub',\n",
       " 'Business_Date']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df11=spark.read.csv('C:/Users/Gaurav/Desktop/Data_Check/cdjobs_loan_monthly_snapshot.csv', header=True, inferSchema=True).dropDuplicates([\"Loan_Account_Number\"])\n",
    "\n",
    "df11.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3fe6d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LOAN_ACCOUNT_NUMBER',\n",
       " 'CUSTOMER_ID',\n",
       " 'RECEIPT_ID',\n",
       " 'RECEIPT_AMOUNT',\n",
       " 'RECEIPT_STATUS',\n",
       " 'HOURLY_TIME_STAMP']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df12=spark.read.csv('C:/Users/Gaurav/Desktop/Data_Check/cdjobs_receipt_hourly_snapshot.csv', header=True, inferSchema=True)\n",
    "df12.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "031348ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df11\u001b[38;5;241m=\u001b[39m\u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/Gaurav/Desktop/Data_Check/New_cd_jobs_loan_monthly_snapshot.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inferSchema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDue_Date\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFINREFERENCE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "df11=spark.read.csv('C:/Users/Gaurav/Desktop/Data_Check/New_cd_jobs_loan_monthly_snapshot.csv', header=True, inferSchema=True).select(\"Due_Date\",\"FINREFERENCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7d0d2af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11=df11.withColumn(\"CycleDay\",df11.Due_Date.substr(-2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "614db327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|  Due_Date|CycleDay|\n",
      "+----------+--------+\n",
      "|07-02-2022|      22|\n",
      "|07-02-2022|      22|\n",
      "|07-02-2022|      22|\n",
      "|07-02-2022|      22|\n",
      "|07-02-2022|      22|\n",
      "|07-02-2022|      22|\n",
      "|07-02-2022|      22|\n",
      "|07-02-2022|      22|\n",
      "|07-02-2022|      22|\n",
      "|07-02-2022|      22|\n",
      "|07-02-2022|      22|\n",
      "|07-02-2022|      22|\n",
      "|07-02-2022|      22|\n",
      "|07-02-2022|      22|\n",
      "|07-02-2022|      22|\n",
      "|07-02-2022|      22|\n",
      "|07-02-2022|      22|\n",
      "|07-02-2022|      22|\n",
      "|07-02-2022|      22|\n",
      "|07-02-2022|      22|\n",
      "+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df11.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab0e3128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Due_Date', 'date')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "from pyspark.sql.functions import to_date\n",
    "df11=spark.read.csv('C:/Users/Gaurav/Desktop/Data_Check/New_cd_jobs_loan_monthly_snapshot.csv', header=True, inferSchema=True).select(\"Due_Date\")\n",
    "df11=df11.withColumn(\"Due_Date\",to_date(df11.Due_Date,'dd-MM-yyyy'))\n",
    "df11.select(\"Due_Date\").dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63ce55a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  Due_Date|\n",
      "+----------+\n",
      "|2022-02-07|\n",
      "|2022-02-07|\n",
      "|2022-02-07|\n",
      "|2022-02-07|\n",
      "|2022-02-07|\n",
      "|2022-02-07|\n",
      "|2022-02-07|\n",
      "|2022-02-07|\n",
      "|2022-02-07|\n",
      "|2022-02-07|\n",
      "|2022-02-07|\n",
      "|2022-02-07|\n",
      "|2022-02-07|\n",
      "|2022-02-07|\n",
      "|2022-02-07|\n",
      "|2022-02-07|\n",
      "|2022-02-07|\n",
      "|2022-02-07|\n",
      "|2022-02-07|\n",
      "|2022-02-07|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df11.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5faae10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "df11 = df11.withColumn(\"TodayMinusDueDate\", datediff(date_format(add_months((from_unixtime(unix_timestamp(lit(\n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d\")), 'yyyy-MM-dd')).cast('date')), 0), \"yyyy-MM-dd\"), col(\"Due_Date\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "06441b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|  Due_Date|TodayMinusDueDate|\n",
      "+----------+-----------------+\n",
      "|2022-02-07|               -3|\n",
      "|2022-02-07|               -3|\n",
      "|2022-02-07|               -3|\n",
      "|2022-02-07|               -3|\n",
      "|2022-02-07|               -3|\n",
      "|2022-02-07|               -3|\n",
      "|2022-02-07|               -3|\n",
      "|2022-02-07|               -3|\n",
      "|2022-02-07|               -3|\n",
      "|2022-02-07|               -3|\n",
      "|2022-02-07|               -3|\n",
      "|2022-02-07|               -3|\n",
      "|2022-02-07|               -3|\n",
      "|2022-02-07|               -3|\n",
      "|2022-02-07|               -3|\n",
      "|2022-02-07|               -3|\n",
      "|2022-02-07|               -3|\n",
      "|2022-02-07|               -3|\n",
      "|2022-02-07|               -3|\n",
      "|2022-02-07|               -3|\n",
      "+----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df11.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cedee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11= df11.withColumn(\"CYCLEDAY\", df.DUE_DATE.substr(-2, 2))\n",
    "df11= df11.withColumn('OS_Amt', when(col('CYCLEDAY') >= date_format(add_months((from_unixtime(unix_timestamp(lit(datetime.datetime.now().strftime(\"%Y-%m-%d\")),\n",
    "                                    'yyyy-MM-dd')).cast('date')), 0), \"dd\"), (col('EMI'))).otherwise(col('OVER_DUE_AMOUNT')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae174168",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11=spark.read.csv('C:/Users/Gaurav/Desktop/Data_Check/New_cd_jobs_loan_monthly_snapshot.csv', header=True, inferSchema=True).select(\"Over_Due_Amount\",\"Due_Date\")\n",
    "df11=df11.withColumn(\"Due_Date1\",to_date(df11.Due_Date,'dd-MM-yyyy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9866c6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11= df11.withColumn(\"CYCLEDAY\", df11.Due_Date1.substr(-2, 2))\n",
    "df11=df11.withColumn(\"EMI\",lit(\"Null\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1b449c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11= df11.withColumn('OS_Amt', when(col('CYCLEDAY') >= date_format(add_months((from_unixtime(unix_timestamp(lit(datetime.datetime.now().strftime(\"%Y-%m-%d\")),\n",
    "                                    'dd-MM-yyyy')).cast('date')), 0), \"dd\"), (col('EMI'))).otherwise(col('OVER_DUE_AMOUNT')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "caf8b29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+----------+--------+----+------+\n",
      "|Over_Due_Amount|  Due_Date| Due_Date1|CYCLEDAY| EMI|OS_Amt|\n",
      "+---------------+----------+----------+--------+----+------+\n",
      "|            0.0|07-02-2022|2022-02-07|      07|Null|   0.0|\n",
      "|           0.84|07-02-2022|2022-02-07|      07|Null|  0.84|\n",
      "|           1.23|07-02-2022|2022-02-07|      07|Null|  1.23|\n",
      "|            0.0|07-02-2022|2022-02-07|      07|Null|   0.0|\n",
      "|            0.0|07-02-2022|2022-02-07|      07|Null|   0.0|\n",
      "|            0.0|07-02-2022|2022-02-07|      07|Null|   0.0|\n",
      "|            0.0|07-02-2022|2022-02-07|      07|Null|   0.0|\n",
      "|            0.0|07-02-2022|2022-02-07|      07|Null|   0.0|\n",
      "|            0.0|07-02-2022|2022-02-07|      07|Null|   0.0|\n",
      "|           0.06|07-02-2022|2022-02-07|      07|Null|  0.06|\n",
      "|            0.0|07-02-2022|2022-02-07|      07|Null|   0.0|\n",
      "|            0.0|07-02-2022|2022-02-07|      07|Null|   0.0|\n",
      "|         9400.0|07-02-2022|2022-02-07|      07|Null|9400.0|\n",
      "|            0.0|07-02-2022|2022-02-07|      07|Null|   0.0|\n",
      "|            0.0|07-02-2022|2022-02-07|      07|Null|   0.0|\n",
      "|            0.0|07-02-2022|2022-02-07|      07|Null|   0.0|\n",
      "|            0.0|07-02-2022|2022-02-07|      07|Null|   0.0|\n",
      "|           2.87|07-02-2022|2022-02-07|      07|Null|  2.87|\n",
      "|            0.0|07-02-2022|2022-02-07|      07|Null|   0.0|\n",
      "|         154.64|07-02-2022|2022-02-07|      07|Null|154.64|\n",
      "+---------------+----------+----------+--------+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df11.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "22ef38d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11=spark.read.csv('C:/Users/Gaurav/Desktop/Data_Check/New_cd_jobs_loan_monthly_snapshot.csv', header=True, inferSchema=True).select(\"Due_Date\")\n",
    "df11=df11.withColumn(\"Due_Date\",lit(\"Null\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c5f89878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Due_Date|\n",
      "+--------+\n",
      "|    Null|\n",
      "|    Null|\n",
      "|    Null|\n",
      "|    Null|\n",
      "|    Null|\n",
      "|    Null|\n",
      "|    Null|\n",
      "|    Null|\n",
      "|    Null|\n",
      "|    Null|\n",
      "|    Null|\n",
      "|    Null|\n",
      "|    Null|\n",
      "|    Null|\n",
      "|    Null|\n",
      "|    Null|\n",
      "|    Null|\n",
      "|    Null|\n",
      "|    Null|\n",
      "|    Null|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df11.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8489f505",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDF = spark.read.csv('C:/Users/Gaurav/Desktop/Testing/*', header=True,inferSchema=True).select(\"BUCKET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2853fbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|BUCKET|\n",
      "+------+\n",
      "|     0|\n",
      "|     1|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     1|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     1|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     1|\n",
      "|     0|\n",
      "|     3|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6670563c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting mitoinstaller\n",
      "  Downloading mitoinstaller-0.0.106.tar.gz (15 kB)\n",
      "Collecting analytics-python\n",
      "  Downloading analytics_python-1.4.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: colorama in c:\\program files\\python310\\lib\\site-packages (from mitoinstaller) (0.4.4)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: python-dateutil>2.1 in c:\\program files\\python310\\lib\\site-packages (from analytics-python->mitoinstaller) (2.8.2)\n",
      "Collecting backoff==1.10.0\n",
      "  Downloading backoff-1.10.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\program files\\python310\\lib\\site-packages (from analytics-python->mitoinstaller) (1.16.0)\n",
      "Collecting requests<3.0,>=2.7\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting monotonic>=1.5\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\gaurav\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0,>=2.7->analytics-python->mitoinstaller) (2.0.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gaurav\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0,>=2.7->analytics-python->mitoinstaller) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gaurav\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0,>=2.7->analytics-python->mitoinstaller) (1.26.8)\n",
      "Using legacy 'setup.py install' for mitoinstaller, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for termcolor, since package 'wheel' is not installed.\n",
      "Installing collected packages: certifi, requests, monotonic, backoff, termcolor, analytics-python, mitoinstaller\n",
      "    Running setup.py install for termcolor: started\n",
      "    Running setup.py install for termcolor: finished with status 'done'\n",
      "    Running setup.py install for mitoinstaller: started\n",
      "    Running setup.py install for mitoinstaller: finished with status 'done'\n",
      "Successfully installed analytics-python-1.4.0 backoff-1.10.0 certifi-2021.10.8 mitoinstaller-0.0.106 monotonic-1.6 requests-2.27.1 termcolor-1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.2 is available.\n",
      "You should consider upgrading via the 'C:\\Program Files\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install mitoinstaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f314e095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mitosheet\n",
    "df=pd.read_csv('cd_jobs_geographical_details.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b1b886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=mitosheet.sheet(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "417e0f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd1079c19cdf456795ebbfafa799227e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MitoWidget(analysis_data_json='{\"analysisName\": \"UUID-5d0d7321-60e9-4916-9485-a132c47b8737\", \"code\": {\"imports…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236dad0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
